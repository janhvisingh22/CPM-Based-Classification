{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8cc500-66c1-4ad7-96e7-a4438b5cfbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e5b79c-e3ca-4811-8d6a-1386cba22738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd478ca6df8d4f55b1da82177885aa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yavis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yavis\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e73a5292d24f809f74125c13168fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31b993a7f7c4a6699847d0e426c10ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e53fa567cf4b9db0a0b134ed43e3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a0fcc896744cb5bc20480a893d55d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Choose Model (Change to \"roberta-base\" or other if needed)\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = DistilBertModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b4d979-b48a-415f-a789-a6ad2146c34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70ad2fe-88e2-4c27-a31d-c53361585671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Function to Generate Embeddings\n",
    "def get_embeddings(texts, batch_size=32, pooling=\"cls\"):\n",
    "    \"\"\"Generate BERT/RoBERTa embeddings for a list of texts.\"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Ensure valid pooling method\n",
    "    if pooling not in [\"cls\", \"mean\"]:\n",
    "        raise ValueError(\"Invalid pooling method. Choose from 'cls' or 'mean'.\")\n",
    "\n",
    "    # Process texts in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient tracking\n",
    "            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}  # Move to GPU if available\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "            # Extract embeddings\n",
    "            if pooling == \"cls\":\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "            elif pooling == \"mean\":\n",
    "                batch_embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "        \n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    # Stack all tensors and convert to NumPy at the end\n",
    "    return torch.cat(all_embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ceb321a-d593-44c1-915c-3621abae964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Load WOS JSON files normally\n",
    "with open(\"./data/processed/wos_train_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wos_train = json.load(f)\n",
    "\n",
    "with open(\"./data/processed/wos_test_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wos_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0de14fa-c0c7-4358-a9d4-ede04097b8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded NYT Train: 1753211 samples\n",
      "✅ Loaded NYT Test: 438303 samples\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load NYT JSONL files line by line\n",
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))  # Convert each line into a dictionary\n",
    "    return data\n",
    "\n",
    "nyt_train = load_jsonl(\"./data/processed/nyt_train.jsonl\")\n",
    "nyt_test = load_jsonl(\"./data/processed/nyt_test.jsonl\")\n",
    "\n",
    "print(f\"✅ Loaded NYT Train: {len(nyt_train)} samples\")\n",
    "print(f\"✅ Loaded NYT Test: {len(nyt_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f13b4f3-5444-4b88-9770-11f2963d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "nyt_train_df = pd.DataFrame(nyt_train)\n",
    "nyt_test_df = pd.DataFrame(nyt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd314ef-f3c4-4a6b-b336-065698b3fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WOS JSON with proper conversion\n",
    "wos_train_df = pd.read_json(\"./data/processed/wos_train_final.json\", orient=\"records\")  \n",
    "wos_test_df = pd.read_json(\"./data/processed/wos_test_final.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbf0bfd-64f0-44e1-8e62-9b04fecac30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=37588, step=1)\n",
      "Index(['text', 'tokens', 'labels', 'level1', 'level2', 'keywords'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(wos_train_df.columns)  # Check actual column names\n",
    "print(nyt_train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a16c4f-f3a5-4105-91bd-ccba98a7638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wos_train))  # Should be <class 'list'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81dcc359-bf8b-4602-b50e-ab95b338ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wos_train[0]))  # Should be <class 'dict'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b66b18-2097-4bec-a3b9-d728ca8e3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten wos_train if it's a nested list\n",
    "if isinstance(wos_train[0], list):  \n",
    "    wos_train = [item for sublist in wos_train for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e12b66-e400-48b8-9aaf-ec8eb161d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['text', 'tokens', 'labels', 'level1', 'level2', 'keywords'])\n"
     ]
    }
   ],
   "source": [
    "print(type(wos_train[0]))  # Should now be a dict\n",
    "print(wos_train[0].keys())  # Check available keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "794a0afe-ba5f-49c0-ad93-817e435d82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [entry[\"text\"] for entry in wos_train] + [entry[\"text\"] for entry in nyt_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd1de36-e62f-48bb-8b66-88765724ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten wos_test if it's a nested list\n",
    "if isinstance(wos_test[0], list):  \n",
    "    wos_test = [item for sublist in wos_test for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0173843-1e87-4a26-b594-e0a0a68f9030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['text', 'tokens', 'labels', 'level1', 'level2', 'keywords'])\n"
     ]
    }
   ],
   "source": [
    "# Check type after flattening\n",
    "print(type(wos_test[0]))  # Should be dict\n",
    "print(wos_test[0].keys())  # Ensure 'text' is a key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ad0c85c-db32-4447-94be-3f5ade245dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test texts\n",
    "test_texts = [entry[\"text\"] for entry in wos_test] + [entry[\"text\"] for entry in nyt_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97ed77-09e1-44bb-914c-7fe44b0d09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   0%|▏                                                  | 224/55963 [25:44<104:18:56,  6.74s/it]"
     ]
    }
   ],
   "source": [
    "train_embeddings = get_embeddings(train_texts)\n",
    "test_embeddings = get_embeddings(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602aa54-b178-4b5a-b88d-995a6656b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Save embeddings\n",
    "torch.save(train_embeddings, \"./data/processed/train_embeddings.pt\")\n",
    "torch.save(test_embeddings, \"./data/processed/test_embeddings.pt\")\n",
    "\n",
    "print(\"✅ Embeddings extracted and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fd184-b68f-4c41-ac96-371d3c45177b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
